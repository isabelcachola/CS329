---
title: "Project 2"
author: 'Group 10: Nathan Caldwell, Isabel Cachola, Edward Gunawan, Weiyi Wang'
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 4
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
library(tidyverse)
require(data.world)
knitr::opts_chunk$set(echo = TRUE)
```
  
## **R Session Info**  

```{r}
sessionInfo()
```

## **Github Link** 
TBD


## **Introduction** 
This dataset combines 2016 election data with basic demographic data from the US census such as race and education. We then perform logistic regression, linear discriminant analysis, quadratic discriminant analysis and K-nearest neighbor analysis to see if any of the predictors are effective in predicting whether Trump or Clinton win the state.

## Linear Discriminant Analysis
```{r}
library(tidyverse)
require(dplyr)
require(data.world)
require(MASS)
project <- "https://data.world/ncaldw01/election-results"

data.world::set_config(cfg_env("DW_API"))

df <- data.world::query(
  data.world::qry_sql("SELECT * FROM electionsdata2"),
  dataset = project
)


sdf = dplyr::select(df, state, votes, votes16_trumpd, votes16_clintonh, pop_vote_winner, at_least_bachelor_s_degree, white_not_latino_population, african_american_population, native_american_population, asian_american_population, population_some_other_race_or_races, latino_population)

sdf = dplyr::mutate(sdf,perc_minority =  african_american_population+ native_american_population+ asian_american_population+ population_some_other_race_or_races+ latino_population)%>%arrange(votes)

# Create a training data set using the 25 states with the lowest number of votes.
training = sdf%>% dplyr::filter(votes<2000000)
testing = sdf%>% dplyr::filter(votes>2000000)

# Use the perc_minority column from the testing data to make a lda model predicting whether Trump or Clinton won that state
election_lda = lda(pop_vote_winner~perc_minority,data = training)
election_lda
election_lda_pred = predict(election_lda,testing)
table(election_lda_pred$class,testing$pop_vote_winner)


renderPlot(plot(election_lda))
```

## Explanation and insights of LDA

You can see from the confusion matrix that this model did not do a very good job predicting whether or not Hillary or Trump won that state. In fact it did a terrible job, 15 incorrect vs 10 correct. There was actually a pretty large disparity between the minority populations that each candidate won in the training dataset, with Hillary states at 28% and Trump states  This may suggest that the training data is not representative of the testing data. In this case, the 25 states with the fewest votes were used to predict the results of the remaining states, which may not be the best way to create a testing data set. We should probably try a different distribution of training/testing data across the 50 states to see if we can get a better model.


## LDA Part2
```{r}
# Create a training set using randomly selected states. In this case I just go with the first 25 states according to alphabetical order.
training = sdf%>% dplyr::filter(state<"Montana")
testing = sdf%>% dplyr::filter(state>"Missouri")

# Use the perc_minority column from the testing data to make a lda model predicting whether Trump or Clinton won that state
election_lda = lda(pop_vote_winner~perc_minority,data = training)
election_lda
election_lda_pred = predict(election_lda,testing)
table(election_lda_pred$class,testing$pop_vote_winner)


renderPlot(plot(election_lda))
```
## Explanation of LDA part 2

We see that the predictions are better than before. 56% accuracy as compared to the previous 40% accuracy. This means that this separation of testing and training data is more appropriate than the previous division. This also suggests that the states with the fewest votes did not follow a similar pattern to the states with more votes, which would explain why the model generated from the training data is not good at predicting the results of the testing data. We will be using these new testing and training sets from now on. (Note: I know I could have chosen the training and testing sets completely randomly using the runif() function, but for the sake of keeping the data consistent, I decided to arbitrarily split it, so that the data would be the same with each run of the RMarkdown file)


## Logistic Regression

```{r}
sdf = dplyr::mutate(sdf,trump1hillary0 = if_else(votes16_trumpd>votes16_clintonh,1,0))

training = sdf%>% dplyr::filter(state>"Montana")
testing = sdf%>% dplyr::filter(state>"Missouri")

perc_min_logis_fit=glm(trump1hillary0~perc_minority, data = training, family = "binomial")
perc_min_logis_probs=predict(perc_min_logis_fit,newdata=testing,type="response") 
perc_min_logis_pred=ifelse(perc_min_logis_probs >0.55,"Trump","Clinton")
winner=testing$pop_vote_winner
table(perc_min_logis_pred,winner)
mean(perc_min_logis_pred==winner)
perc_min_logis_probs
renderPlot(ggplot(testing,aes(x=perc_minority,y=trump1hillary0))+geom_point()+stat_smooth(method="glm",method.args=list(family="binomial"),se=F))
```

## Quadratic Discriminate Analysis

```{r}
election_qda = qda(pop_vote_winner~perc_minority,data = training)
election_qda_pred = predict(election_qda,testing)
table(election_qda_pred$class,testing$pop_vote_winner)
```

## K-nearest neighbor

```{r}
require(class)

perc_min_knn_pred=knn(data.frame(training$perc_minority),data.frame(testing$perc_minority),training$pop_vote_winner,k=5)

table(perc_min_knn_pred,testing$pop_vote_winner)
#mean(perc_min_knn_pred==training$pop_vote_winner)
```

## Summary of findings
The results of these models indicate that the percentage of minorities in states are not a strong predictor for whether Hillary clinton won states, but it is a fairly good predictor within the states that Trump won during the election. In the states that Hillary won, the models only predicted correctly about 50% of the time, basically a coin flip. But in the states that Trump won, the models frequently predicted his victory with 80% accuracy or better. This indicates that the racial demographics of Trump supporters is much more concentrated and distinct than those of Hillary supporters among the different states.

Out of the 4 different models which used percent minority as a predictor for whether Hillary or Trump won the state, k nearest neighbor was the most accurate.

```{r eruptions}
inputPanel(
  selectInput("n_breaks", label = "Number of bins:",
              choices = c(10, 20, 35, 50), selected = 20),
  
  sliderInput("bw_adjust", label = "Bandwidth adjustment:",
              min = 0.2, max = 2, value = 1, step = 0.2)
)

renderPlot({
  hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),
       xlab = "Duration (minutes)", main = "Geyser eruption duration")
  
  dens <- density(faithful$eruptions, adjust = input$bw_adjust)
  lines(dens, col = "blue")
})
```

## Embedded Application

It's also possible to embed an entire Shiny application within an R Markdown document using the `shinyAppDir` function. This example embeds a Shiny application located in another directory:

```{r tabsets}
shinyAppDir(
  system.file("examples/06_tabsets", package = "shiny"),
  options = list(
    width = "100%", height = 900
  )
)
```

Note the use of the `height` parameter to determine how much vertical space the embedded application should occupy.

You can also use the `shinyApp` function to define an application inline rather then in an external directory.

In all of R code chunks above the `echo = FALSE` attribute is used. This is to prevent the R code within the chunk from rendering in the document alongside the Shiny components.

## Inputs and Outputs 2

```{r eruptions2}
inputPanel(
  selectInput("n_breaks2", label = "Number of bins:",
              choices = c(10, 20, 35, 50), selected = 20),
  
  sliderInput("bw_adjust2", label = "Bandwidth adjustment:",
              min = 0.2, max = 2, value = 1, step = 0.2)
)

renderPlot({
  hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks2),
       xlab = "Duration (minutes)", main = "Geyser eruption duration")
  
  dens <- density(faithful$eruptions, adjust = input$bw_adjust2)
  lines(dens, col = "blue")
})
```


