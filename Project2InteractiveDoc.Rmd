---
title: "Project 2"
author: 'Group 10: Nathan Caldwell, Isabel Cachola, Edward Gunawan, Weiyi Wang'
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 4
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
library(tidyverse)
require(data.world)
knitr::opts_chunk$set(echo = TRUE)
```
  
## **R Session Info**  

```{r}
sessionInfo()
```

## **Github Link** 
TBD


## **Introduction** 
This dataset combines 2016 election data with basic demographic data from the US census such as race and education. We then perform logistic regression, linear discriminant analysis, quadratic discriminant analysis and K-nearest neighbor analysis to see if any of the predictors are effective in predicting whether Trump or Clinton win the state.

## **Minority Population**{.tabset .tabset-fade}

### Linear Discriminant Analysis
```{r}
library(tidyverse)
require(dplyr)
require(data.world)
require(MASS)
project <- "https://data.world/ncaldw01/election-results"

data.world::set_config(cfg_env("DW_API"))

df <- data.world::query(
  data.world::qry_sql("SELECT * FROM electionsdata2"),
  dataset = project
)


sdf = dplyr::select(df, state, votes, votes16_trumpd, votes16_clintonh, pop_vote_winner, at_least_bachelor_s_degree, white_not_latino_population, african_american_population, native_american_population, asian_american_population, population_some_other_race_or_races, latino_population)

sdf = dplyr::mutate(sdf,perc_minority =  african_american_population+ native_american_population+ asian_american_population+ population_some_other_race_or_races+ latino_population)%>%arrange(votes)

# Create a training data set using the 25 states with the lowest number of votes.
training = sdf%>% dplyr::filter(votes<2000000)
testing = sdf%>% dplyr::filter(votes>2000000)

# Use the perc_minority column from the testing data to make a lda model predicting whether Trump or Clinton won that state
election_lda = lda(pop_vote_winner~perc_minority,data = training)
election_lda
election_lda_pred = predict(election_lda,testing)
table(election_lda_pred$class,testing$pop_vote_winner)


renderPlot(plot(election_lda))
```

### Explanation and insights of LDA

You can see from the confusion matrix that this model did not do a very good job predicting whether or not Hillary or Trump won that state. In fact it did a terrible job, 15 incorrect vs 10 correct. There was actually a pretty large disparity between the minority populations that each candidate won in the training dataset, with Hillary states at 28% and Trump states  This may suggest that the training data is not representative of the testing data. In this case, the 25 states with the fewest votes were used to predict the results of the remaining states, which may not be the best way to create a testing data set. We should probably try a different distribution of training/testing data across the 50 states to see if we can get a better model.


### LDA Part2
```{r}
# Create a training set using randomly selected states. In this case I just go with the first 25 states according to alphabetical order.
training = sdf%>% dplyr::filter(state<"Montana")
testing = sdf%>% dplyr::filter(state>"Missouri")

# Use the perc_minority column from the testing data to make a lda model predicting whether Trump or Clinton won that state
election_lda = lda(pop_vote_winner~perc_minority,data = training)
election_lda
election_lda_pred = predict(election_lda,testing)
table(election_lda_pred$class,testing$pop_vote_winner)


renderPlot(plot(election_lda))
```
### Explanation of LDA part 2

We see that the predictions are better than before. 56% accuracy as compared to the previous 40% accuracy. This means that this separation of testing and training data is more appropriate than the previous division. This also suggests that the states with the fewest votes did not follow a similar pattern to the states with more votes, which would explain why the model generated from the training data is not good at predicting the results of the testing data. We will be using these new testing and training sets from now on. (Note: I know I could have chosen the training and testing sets completely randomly using the runif() function, but for the sake of keeping the data consistent, I decided to arbitrarily split it, so that the data would be the same with each run of the RMarkdown file)


### Logistic Regression

```{r}
sdf = dplyr::mutate(sdf,trump1hillary0 = if_else(votes16_trumpd>votes16_clintonh,1,0))

training = sdf%>% dplyr::filter(state>"Montana")
testing = sdf%>% dplyr::filter(state>"Missouri")

perc_min_logis_fit=glm(trump1hillary0~perc_minority, data = training, family = "binomial")
perc_min_logis_probs=predict(perc_min_logis_fit,newdata=testing,type="response") 
perc_min_logis_pred=ifelse(perc_min_logis_probs >0.55,"Trump","Clinton")
winner=testing$pop_vote_winner
table(perc_min_logis_pred,winner)
mean(perc_min_logis_pred==winner)
perc_min_logis_probs
renderPlot(ggplot(testing,aes(x=perc_minority,y=trump1hillary0))+geom_point()+stat_smooth(method="glm",method.args=list(family="binomial"),se=F))
```

### Quadratic Discriminate Analysis

```{r}
election_qda = qda(pop_vote_winner~perc_minority,data = training)
election_qda_pred = predict(election_qda,testing)
table(election_qda_pred$class,testing$pop_vote_winner)
```

### K-nearest neighbor

```{r}
require(class)

perc_min_knn_pred=knn(data.frame(training$perc_minority),data.frame(testing$perc_minority),training$pop_vote_winner,k=5)

table(perc_min_knn_pred,testing$pop_vote_winner)
#mean(perc_min_knn_pred==training$pop_vote_winner)
```



### Summary of findings
The results of these models indicate that the percentage of minorities in states are not a strong predictor for whether Hillary clinton won states, but it is a fairly good predictor within the states that Trump won during the election. In the states that Hillary won, the models only predicted correctly about 50% of the time, basically a coin flip. But in the states that Trump won, the models frequently predicted his victory with 80% accuracy or better. This indicates that the racial demographics of Trump supporters is much more concentrated and distinct than those of Hillary supporters among the different states.

Out of the 4 different models which used percent minority as a predictor for whether Hillary or Trump won the state, k nearest neighbor was the most accurate.

```{r eruptions}
inputPanel(
  selectInput("n_breaks", label = "Number of bins:",
              choices = c(10, 20, 35, 50), selected = 20),
  
  sliderInput("bw_adjust", label = "Bandwidth adjustment:",
              min = 0.2, max = 2, value = 1, step = 0.2)
)

renderPlot({
  hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),
       xlab = "Duration (minutes)", main = "Geyser eruption duration")
  
  dens <- density(faithful$eruptions, adjust = input$bw_adjust)
  lines(dens, col = "blue")
})
```

##

## **Third Party Voting**{.tabset .tabset-fade}

### Overview

The goal of this section is to try to understand how third party voting may have affected the election.

In summary:

- Percentage of third party votes in general is a poor predictor of who won the state

- Percentage of votes for Gary Johnson is also a poor predictor of who won the state

- More interestingly, percentage of votes for Jill Stein is a relatively good predictor of who won the state

##


## Predicition of Election through Uneployment and Uninsured Rates
There are many different predictors that would help deterime whether a state would vote Hillary or Trump. However two factors that stand out are the unemployed and the uninsured. The unemployment rate and the uninsured rate are always central topics in elections, and this election was no different. Two major issues that were relevent to this election was wage inequality and universal health care, which are tide directly with unemployment and and uninsured. We wanted to see how the rates of these two factors effected which candidate won in each state. In the confusion matrix, 1 stands for Trump and 0 stands for Hillary. For the sake of this experiment 30 of the 50 states were used for training and the other 20 were used for testing

The following graph shows the states Trump won and which states Hillary one, and where that state liew in terms of uninsured rates and unemployement rates

```{r}
require(MASS)
require(ISLR)
require(tidyverse)
require(dplyr)
require(class)
require(ggplot2)

project<- "https://data.world/ncaldw01/election-results"
Edf <- read.csv("https://query.data.world/s/9AePdX0-UXY6R90eqhjXNuTAA1imZ9", header=TRUE, stringsAsFactors=FALSE);
#names(Edf)

Edf2= Edf %>% dplyr::select(State, pop_vote_winner, Uninsured, Unemployment) %>% dplyr::mutate(winner=ifelse(pop_vote_winner=="Trump", 1, 0))

#Edf_train <- Edf2[sample(nrow(Edf2), 30),]
#Edf_test <- subset(Edf2, !is.element(Edf2$State, Edf_train$State))
Edf_test = Edf2[1:19,]
Edf_train = Edf2[20:50,]

renderPlot(ggplot(Edf_test, aes(x = Unemployment, y = Uninsured, colour = winner>0))+ geom_point() + scale_colour_manual(name = 'Candidate', labels = c("Hillary", "Trump"), values = setNames(c('red','blue'),c(T,F))))


```

The mean and confustion matrix for a logistic regression are as follow. The graphs below show which points were guessed correctly and incorrectly:

```{r}
#logistic Regression
Elogreg2 = glm(winner ~ Uninsured + Unemployment, data = Edf_train, family = binomial)
Elogreg2_pred = predict(Elogreg2, newdata = Edf_test, type = "response")
Elogreg2_pred = ifelse(Elogreg2_pred>0.5,1,0) %>% data.frame()
mean(Elogreg2_pred$.== Edf_test$winner)#0.75
table(Elogreg2_pred$., Edf_test$winner)
Elogreg_comb = cbind(Edf_test, Elogreg2_pred)%>% mutate(Correct = ifelse(winner == ., 0, 1))

renderPlot(ggplot(Elogreg_comb, aes(x = Unemployment, y = Uninsured, colour = Correct>0))+ geom_point() + scale_colour_manual(name = 'Correct', labels = c("Correct", "Incorrect"), values = setNames(c('Orange','black'),c(T,F))))

```

The Logisitic Regression has an 89.5% accuracy, meaning that using this model predicted whether or not a state would vote Trump or Hillary with a very high degree of accuracy.


Linear Discriminant Analysis is as follows

```{r}

#Linear Discriminant Analysis
Elda1 = lda( winner ~ Uninsured + Unemployment, data = Edf_train)
Elda.preds = predict(Elda1,Edf_test) %>% data.frame() 

mean(Elda.preds$class==Edf_test$winner)
table(Elda.preds$class, Edf_test$winner)
Elda.preds = cbind(Edf_test, Elda.preds)%>% mutate(Correct = ifelse(winner == class, 0, 1))


renderPlot(ggplot(Elda.preds, aes(x = Unemployment, y = Uninsured, colour = Correct>0))+ geom_point() + scale_colour_manual(name = 'Correct', labels = c("Correct", "Incorrect"), values = setNames(c('Orange','black'),c(T,F))))

```

The Linear Regression has an 89.5% accuracy. This model also has a very high predictor of which candidate would win the election.


Quadratic Discriminant Analysis is as follows

```{r}

#Quadratic Discriminant Analysis
Eqda1 = qda( winner ~ Uninsured + Unemployment, data = Edf_train)
Eqda.preds = predict(Eqda1,Edf_test) %>% data.frame()
mean(Eqda.preds$class==Edf_test$winner)
table(Eqda.preds$class, Edf_test$winner)
Eqda.preds = cbind(Edf_test, Eqda.preds)%>% mutate(Correct = ifelse(winner == class, 0, 1))


renderPlot(ggplot(Eqda.preds, aes(x = Unemployment, y = Uninsured, colour = Correct>0))+ geom_point() + scale_colour_manual(name = 'Correct', labels = c("Correct", "Incorrect"), values = setNames(c('Orange','black'),c(T,F)))
)

```

The Quadratic Discrimant Analysis has an 84.2% accuracy. This model did well but not as well as the Linear Regression or the Logistic Regression.


KNN Linear Discriminant Analysis is as follows

```{r}

#K Nearest Neighbors Analysis
attach(Edf2)
vbind = cbind(Uninsured, Unemployment)
train_comb = State>'Maine'
knn.pred=knn(vbind[train_comb,],vbind[!train_comb,],pop_vote_winner[train_comb],k=5)
knn.pred2 = knn.pred %>% data.frame
table(knn.pred,pop_vote_winner[!train_comb])
mean(knn.pred==pop_vote_winner[!train_comb])
knn.pred2 = cbind(Edf_test, knn.pred2) %>% dplyr::mutate(result=ifelse(.=="Trump", 1, 0)) %>% dplyr::mutate(correct = ifelse(winner == result, 0, 1))


renderPlot(ggplot(knn.pred2, aes(x = Unemployment, y = Uninsured, colour = correct>0))+ geom_point() + scale_colour_manual(name = 'Correct', labels = c("Correct", "Incorrect"), values = setNames(c('Orange','black'),c(T,F))))



```

The KNN alaysis with K = 5 has an accuracy of 78%. This model did not do a very good job of predicting whether a state would vote Hillary or Trump in comparison to the other models.

Summary

In Summary, for these particular variables, uninsured and unemployed the Linear Discriminant Analysis as well as the Logistic Regression predicted which candidiate would end up winning in each state. 

